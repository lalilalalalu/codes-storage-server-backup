- codes-storage-server depends on ROSS and CODES software packages.
  Instructions on how to install ROSS and CODES can be found at:

https://xgitlab.cels.anl.gov/codes/codes/wikis/installation

- Build codes-storage-server

if use branch "makefix" then skip step 1 and 2
1.Changes Makefile:
AM_CPPFLAGS = ${CODES_CFLAGS} ${ROSS_CFLAGS}
LDADD = $(lib_LTLIBRARIES) ${CODES_LIBS} ${ROSS_LIBS}

2.Changes Configure.ac
add PKG_CHECK_MODULES_STATIC([ROSS], [ross], [], [AC_MSG_ERROR([Could not find working ross installation via pkg-config])])


./prepare.sh

mkdir build

cd build 

../configure PKG_CONFIG_PATH=/path/to/codes/install/lib/pkgconfig
CC=mpicc CXX=mpicxx CCLD=mpicxx CFLAGS=-g -O0 --prefix=/path/to/codes-storage-server/install

../configure PKG_CONFIG_PATH=/home/flash/codes-dev/codes/build/lib/pkgconfig:/home/flash/codes-dev/build-ross/lib/pkgconfig CC=mpicc CXX=mpicxx CCLD=mpicxx CFLAGS=-g --prefix=/home/flash/codes-dev/codes

make -j 3

make install

- Running the burst buffer simulation :

Running the simulation requires a simulation configuration file, a workload
file and a job allocation file. Here are the details on each of these files:

--> Simulation configuration files (Can be found in checkpoint-study/config-files):
    * One file is for adaptive routing and the other is for minimal routing.
    *
    * Here is a detailed explanation of various configuration sections in the
    * file:
    * The LPGROUPS is for the mapping of LPs on the MPI processes. It also
    * tells which network nodes will be burst buffers and which ones will be
    * compute nodes.
    * 
    * The PARAMS part of the config file tells the dragonfly network model about the
    * number of network nodes, bandwidth, routing, virtual channel buffer space. 
    * Please adjust the HOME_CODES to your home directory where CODES is
    * installed.
    * 
    * The codes-store part is the configuration of the burst buffer nodes.
    * There is a certain number of threads to multiplex the transfers over
    * (default is 4). Memory size is the amount of RAM and storage size is the
    * burst buffer storage available (default is 6.4 TB).
    *
    * The resource part is a counter that maintains track of storage in the
    * burst buffer node.
    *
    * LSM is the local storage model (similar to a disk). This can be used to
    * specify the read/write bandwidth of the SSD device.
    * 
    * test-checkpoint-client is for configuring the aggregate checkpoint size
    * (default is 1TB), checkpoint write bandwidth, mean time to interrupt and
    * the number of iterations.
--> Workload files (Can be found in checkpoint-study/workload-files)
    * Each line provides information on a job as to how many ranks will be
    * involved and which workload will be assigned to the job. Workload type
    * must be either checkpoint (for I/O) or synthetic (for background
    * communication traffic).

--> Job Allocation files (Can be found in checkpoint-study/allocation_files)
    * The job allocation file has a list of ranks as to which ranks will be
    * involved in each job (Each line represents a job). This must map to the 
    * information in the workload file.

--> Using the lp-io-dir directs the data generated by the simulation to the
    * specified directory. Currently, data on network link traffic and
    * saturation, network nodes and burst buffer nodes is generated. For
    * network latency, see dragonfly-msg-stats.meta (and data file). 
    * For checkpoint traffic statistics, see checkpoint-client-stats.meta (and 
    * data file in directory). 

--> Command line to run the simulation:

./src/client/client-mul-wklds --sync=1
--workload-conf-file=$HOME_CODES/codes-storage-server/checkpoint-study/workload-files/workload-512.conf
--rank-alloc-file=cont-alloc-9702-2048.conf
--codes-config=$HOME_CODES/codes-storage-server/checkpoint-study/config-files/test-checkpoint-dfly-1T.conf
--lp-io-dir=test-checkpoint
--lp-io-use-suffix=1 

--> For generating job scripts on clusters, see job-generation-scripts.

--> Generate job allocation files from scratch using job placement policies, see codes/scripts/allocation_gen/README 
